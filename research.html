---
layout: common
title: Research
tabname: Research
---

<div class="row">
  <div class="col-md-12">
    <h1 class="page-header">Research</h1>
    <p>
      My current research interests are <strong>Large-Scale Optimization</strong>, <strong>Machine Learning</strong>, <strong>Transportation</strong>,
      <strong>Data Analytics</strong> and applications to <strong>Airline</strong>,<strong> Urban Transportation</strong> and <strong>Power System</strong> .
    </p>
    <h2>Published Work</h2>

    <div class="panel-group" id="published">
      <div class="panel panel-default">
        <div class="panel-heading">
          <a data-toggle="collapse" data-parent="#published" href="#collapse4">
            Wei, K., V. Vaze, and A. Jacquillat
            <em>Airline Timetable Development and Fleet Assignment Incorporating Passenger Choice</em> (2019) 
            <strong>Transportation Science</strong> 2019, in Press.
          </a><br />
          <i class="material-icons md-18">bookmark</i> <a href="https://agifors.org/news/8092026">Winner of the 2019 Anna Valicek Award</a><br />
        </div>
        <div id="collapse4" class="panel-collapse collapse">
          <div class="panel-body">
                <p>
                  <strong>Abstract:</strong> Flight timetabling can greatly impact an airline’s operating profit, yet data-driven or model-based solutions to support it remain limited. Timetabling optimization is significantly complicated by two factors. First, it exhibits strong interdependencies with subsequent fleet assignment decisions of the airlines. Second, flights’ departure and arrival times are important determinants of passenger connection opportunities, of the attractiveness of each (nonstop or connecting) itinerary, and, in turn, of passengers’ booking decisions. Because of these complicating factors, most existing approaches rely on incremental timetabling. This paper introduces an original integrated optimization approach to comprehensive flight timetabling and fleet assignment under endogenous passenger choice. Passenger choice is captured by a discrete-choice generalized attraction model. The resulting optimization model is formulated as a mixed-integer linear program. This paper also proposes an original multiphase solution approach, which effectively combines several heuristics, to optimize the network-wide timetable of a major airline within a realistic computational budget. Using case study data from Alaska Airlines, computational results suggest that the combination of this paper’s model formulation and solution approaches can result in significant profit improvements as compared with the most advanced incremental approaches to flight timetabling. Additional computational experiments based on several extensions also demonstrate the benefits of this modeling and computational framework to support various types of strategic airline decision making in the context of frequency planning, revenue management, and postmerger integration. 
                </p>
                <p style="text-align: center;">
                  <a href="https://scholar.google.com/citations?user=9ULbBLEAAAAJ&hl=en#d=gs_md_cita-d&u=%2Fcitations%3Fview_op%3Dview_citation%26hl%3Den%26user%3D9ULbBLEAAAAJ%26citation_for_view%3D9ULbBLEAAAAJ%3Au-x6o8ySG0sC%26tzom%3D-480"><button type="button" class="btn btn-primary btn-lg">Paper</button></a>
                  <a href="https://agifors.org/resources/Documents/Symposium%202019/AnnaValicek/10-Keji%20%20Wei%20-%20Paper.pdf"><button type="button" class="btn btn-primary btn-lg">Get Manuscript</button></a>
                  <a href="https://techxplore.com/news/2020-01-tool-flight-choices-airline-profits.html"><button type="button" class="btn btn-primary btn-lg">Media Exposure</button></a>
                </p>
          </div>
        </div>
      </div>

      <div class="panel panel-default">
        <div class="panel-heading">
            <a data-toggle="collapse" data-parent="#published" href="#collapse3">
              Harder, R., K. Wei, V. Vaze, and J. Stahl(2019)
              <em>Simulation Analysis and Comparison of Point of Care Testing and Central Laboratory Testing
              </em>. 
              <strong>Medical Decision Making: Policy & Practice</strong>  4(1), 1–14.
            </a>
        </div>
        <div id="collapse3" class="panel-collapse collapse">
          <div class="panel-body">
                <p>
                    <strong>Abstract:</strong> Background. In response to demand for fast and efficient clinical testing, the use of point-of-care testing (POCT) has become increasingly common in the United States. However, studies of POCT implementation have found that adopting POCT may not always be advantageous relative to centralized laboratory testing. Methods. We construct a simulation model of patient flow in an outpatient care setting to evaluate tradeoffs involved in POCT implementation across multiple dimensions, comparing measures of patient outcomes in varying clinical scenarios, testing regimes, and patient conditions. Results. We find that POCT can significantly reduce clinical time for patients, as compared to traditional testing regimes, in settings where clinic and central testing areas are far apart. However, as distance from clinic to central testing area decreased, POCT advantage over central laboratory testing also decreased, in terms of time in the clinical system and estimated subsequent productivity loss. For example, testing for pneumonia resulted in an estimated average of 27.80 (central lab) versus 15.50 (POCT) total lost productive hours in a rural scenario, and an average of 14.92 (central lab) versus 15.50 (POCT) hours in a hospital-based scenario. Conclusions. Our results show that POCT can effectively reduce the average time a patient spends in the system for varying condition profiles and clinical scenarios. However, the number of total lost productive hours, a more holistic measure, is greatly affected by testing quality, where POCT often is at a disadvantage. Thus, it is important to consider factors such as clinical setting, target condition, testing costs, and test quality when selecting appropriate testing regime.
                </p>
                <p style="text-align: center;">
                  <a href="https://journals.sagepub.com/doi/full/10.1177/2381468319856306"><button type="button" class="btn btn-primary btn-lg">Get Paper</button>
                </p>
          </div>
        </div>
      </div>

      
      <div class="panel panel-default">
        <div class="panel-heading">
          <a data-toggle="collapse" data-parent="#published" href="#collapse2">
            Wei, K., and V. Vaze (2018)
              <em>Modeling Crew Itineraries and Delays in the National Air Transportation System</em>.
              <strong>Transportation Science</strong> 52(5), 1276–1296.
          </a><br />
          <i class="material-icons md-18">bookmark</i> <a href="https://agifors.org/PriorAwardWinners"> Second Place Winner of the 2017 Anna Valicek Award</a><br />
        </div>
        <div id="collapse2" class="panel-collapse collapse">
          <div class="panel-body">
                <p>
                    <strong>Abstract:</strong> We propose, optimize, and validate a methodological framework for estimating the extent of the crew-propagated delays and disruptions (CPDDs). We identify the
                    factors that influence the extent of the CPDDs and incorporate them into a robust crewscheduling model. We develop a fast heuristic approach for solving the inverse of this
                    robust crew-scheduling problem to generate crew schedules that are similar to real-world
                    crew-scheduling samples. We develop a sequence of exact and heuristic techniques to
                    quickly solve the forward problem within a small optimality gap for network sizes that
                    are among the largest in robust crew-scheduling literature. Computational results using
                    four large real-world airline networks demonstrate that the crew schedules produced by
                    our approach generate propagation patterns similar to those observed in the real world.
                    Extensive out-of-sample validation tests indicate that the parameters calibrated for one
                    network perform reasonably well for other networks. We provide new insights into the
                    perceived trade-off between planned costs and delay costs as reflected by actual airline
                    crew schedules. Finally, we present a general approach to estimate the CPDDs for any
                    given network using our methodological framework under a variety of data availability
                    scenarios.
                </p>
                <p style="text-align: center;">
                  <a href="https://pubsonline.informs.org/doi/10.1287/opre.2018.1763"><button type="button" class="btn btn-primary btn-lg">Get Paper</button><a href="assets/papers/201803taxipaper.pdf"><button type="button" class="btn btn-primary btn-lg">Manuscript</button></a>
                </p>
          </div>
        </div>
      </div>
      
      <div class="panel panel-default">
        <div class="panel-heading">
            <a data-toggle="collapse" data-parent="#published" href="#collapse1">
              J. Reilly, S. Martin, M. Payer, A. Bayen (2016). 
              <em>Creating complex congestion patterns via multi-objective optimal freeway traffic control with application to cyber-security</em>. 
              <strong>Transportation Research Part B: Methodological</strong>, 91, 366-382.
            </a>
        </div>
        <div id="collapse1" class="panel-collapse collapse">
          <div class="panel-body">
            <div class="row">
              <div class="col-md-4">
                  <img src="assets/img/cal_logo.jpg" class="img-responsive" alt="Cal logo reproduced with congestion patterns" />
              </div>
              <div class="col-md-8">
                <p>
                  <strong>Abstract:</strong> This article presents a study on freeway networks instrumented with coordinated ramp metering and the ability of such control systems
                  to produce arbitrarily complex congestion patterns within the dynamical limits of the traffic system. The developed method is used to
                  evaluate the potential for an adversary with access to control infrastructure to enact high-level attacks on the underlying freeway system. 
                  The attacks are executed using a predictive, coordinated ramp metering controller based on finite-horizon optimal control 
                  and multi-objective optimization techniques. The efficacy of the control schemes in carrying out the prescribed attacks is determined
                  via simulations of traffic network models based on the cell transmission model with onramps modeled as queue buffers. 
                  Freeway attacks with high-level objectives are presented on two illustrative examples: congestion-on-demand, 
                  which aims to create precise, user-specified pockets of congestion, and catch-me-if-you-can, which attempts to aid a fleeing vehicle from pursuant vehicles.
                </p>
                <p style="text-align: center;">
                    <a href="https://www.sciencedirect.com/science/article/pii/S0191261516303307"><button type="button" class="btn btn-primary btn-lg">Get Paper</button>
                    </a>
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <h2>Manuscripts</h2>
    <div class="panel-group" id="manuscripts">
      <div class="panel panel-default">
          <div class="panel-heading">
            <a data-toggle="collapse" data-parent="#manuscripts" href="#collapse2019priceof">
              D. Bertsimas, A. Delarue, P. Jaillet, S. Martin.
              <em>The Price of Interpretability</em> (2019) arXiv:1907.03419
            </a>
          </div>
          <div id="collapse2019priceof" class="panel-collapse collapse">
            <div class="panel-body">
              <div class="row">
                <div class="col-md-4">                  
                  <img src="assets/img/2019priceofinterpretability.png" class="img-responsive" alt="Examples of incremental model spaces." />
                </div>
                <div class="col-md-8">
                  <p>
                    <strong>Abstract:</strong> When quantitative models are used to support decision-making on complex and important topics, understanding a model's ``reasoning'' can increase trust in its predictions, expose hidden biases, or reduce vulnerability to adversarial attacks. However, the concept of interpretability remains loosely defined and application-specific. In this paper, we introduce a mathematical framework in which machine learning models are constructed in a sequence of interpretable steps. We show that for a variety of models, a natural choice of interpretable steps recovers standard interpretability proxies (e.g., sparsity in linear models). We then generalize these proxies to yield a parametrized family of consistent measures of model interpretability. This formal definition allows us to quantify the ``price'' of interpretability, i.e., the tradeoff with predictive accuracy. We demonstrate practical algorithms to apply our framework on real and synthetic datasets.
                  </p>
                  <p style="text-align: center;">
                    <a href="https://arxiv.org/abs/1907.03419"><button type="button" class="btn btn-primary btn-lg">Get Manuscript</button></a>
                  </p>
                </div>
              </div>
            </div>
          </div>
      </div>
      <div class="panel panel-default">
          <div class="panel-heading">
            <a data-toggle="collapse" data-parent="#manuscripts" href="#collapse2019optimalexplanations">
              D. Bertsimas, A. Delarue, P. Jaillet, S. Martin.
              <em>Optimal Explanations of Linear Models</em> (2019) arXiv:1907.04669
            </a>
          </div>
          <div id="collapse2019optimalexplanations" class="panel-collapse collapse">
            <div class="panel-body">
              <div class="row">
                <div class="col-md-4">                  
                  <img src="assets/img/2019optimalexplanations.png" class="img-responsive" alt="Coordinate path illustration." />
                </div>
                <div class="col-md-8">
                  <p>
                    <strong>Abstract:</strong> When predictive models are used to support complex and important decisions, the ability to explain a model's reasoning can increase trust, expose hidden biases, and reduce vulnerability to adversarial attacks. However, attempts at interpreting models are often ad hoc and application-specific, and the concept of interpretability itself is not well-defined. We propose a general optimization framework to create explanations for linear models. Our methodology decomposes a linear model into a sequence of models of increasing complexity using coordinate updates on the coefficients. Computing this decomposition optimally is a difficult optimization problem for which we propose exact algorithms and scalable heuristics. By solving this problem, we can derive a parametrized family of interpretability metrics for linear models that generalizes typical proxies, and study the tradeoff between interpretability and predictive accuracy.
                  </p>
                  <p style="text-align: center;">
                    <a href="https://arxiv.org/abs/1907.04669"><button type="button" class="btn btn-primary btn-lg">Get Manuscript</button></a>
                  </p>
                </div>
              </div>
            </div>
          </div>
      </div>
    </div>

    <h2>Other</h2>
    <div class="panel-group" id="other">
      <div class="panel panel-default">
        <div class="panel-heading">
            <a data-toggle="collapse" data-parent="#other" href="#phdthesis">
              PhD thesis: The Edge of Large-Scale Optimization in Transportation and Machine Learning
            </a><br />
            (formerly <em>Committee: Dr. Jaime Carbonell, Dr. Tom Mitchell, Dr. Larry Wasserman, and Dr. Robert Tibshirani (from Stanford)</em>) <br />
        </div>
        <div id="phdthesis" class="panel-collapse collapse">
          <div class="panel-body">
            This thesis focuses on impactful applications of large-scale optimization in transportation and machine learning. 
            Using both theory and computational experiments, we introduce novel optimization algorithms to overcome the tractability issues that arise in real world applications. 
            We work towards the implementation of these algorithms, through software contributions, public policy work, and a formal study of machine learning interpretability.
            Our implementation in Boston Public Schools generates millions of dollars in yearly transportation savings and led to important public policy consequences in the United States.
            
            This work is motivated by large-scale transportation problems that present significant optimization challenges.
            In particular, we study the problem of ride-sharing, the online routing of hundreds of thousands of customers every day in New York City. 
            We also contribute to travel time estimation from origin-destination data, on city routing networks with tens of thousands of roads.
            We additionally consider the problem of school transportation, the scheduling of hundreds of buses to send tens of thousands of children to school everyday. 
            This transportation problem is related to the choice of school start times, for which we also propose an optimization framework.
            
            Building on these applications, we present methodological contributions in large-scale optimization.
            We introduce state-of-the-art algorithms for scheduling problems with time-window (<em>backbone</em>) and for school bus routing (<em>BiRD</em>).
            Our work on travel time estimation tractably produces solutions to the inverse shortest path length problem, solving a sequence of second order cone problems.
            We also present a theoretical and empirical study of the stochastic proximal point algorithm, an alternative to stochastic gradient methods (the de-facto algorithm for large-scale learning).
            
            We also aim at the implementation of these algorithms, through software contributions, public policy work (together with stakeholders and journalists), and a collaboration with the city of Boston.
            Explaining complex algorithms to decision-makers is a difficult task, therefore we introduce an optimization framework to decomposes models into a sequence of simple building blocks. 
            This allows us to introduce formal measure of the "interpretability" of a large class of machine learning models, and to study tradeoffs between this measure and model performance, the <em>price of interpretability</em>.
            <p style="text-align: center;">
              <a href="assets/papers/sebastienmartin_thesis.pdf"><button type="button" class="btn btn-primary btn-lg">Get Thesis</button></a>
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>